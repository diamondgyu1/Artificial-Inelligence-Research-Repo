{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Notes\n",
    "1. kind of A2C with target notwork -> 4 networks are used\n",
    "\n",
    "`target network`란? <br><br>\n",
    "on-policy method를 사용하면서 policy나 Q-function을 실시간으로 업데이트하면\n",
    "training와중에 q함수가 계속 바뀌게 되고, 그러면 tranining stability에 좋지 않은 영향을 끼친다.<br><br>\n",
    "따라서 off-policy처럼 학습하는 네트워크와 행동하는 네트워크를 분리한 뒤\n",
    "행동 네트워크가 산출한 action에 따라 행동하고, 업데이트는 학습 네트워크에 한다.\n",
    "주기적으로 학습 네트워크를 행동 네트워크게 덮어씌워준다. (아니면 학습이 안되니까...)<br><br>\n",
    "이때 행동 네트워크를 target network라고 부른다.<br><br>\n",
    "DQN 눈문에서는 네트워크를 통으로 덮어씌웠는데, DDPG논문에서는 tau라는 값을 이용해서\n",
    "tau만큼은 학습 네트워크를 반영하고, 1-tau만큼은 원래 네트워크를 반영하는 방식으로 soft update를 한다.\n",
    "\n",
    "2. actor(policy) output is not pdf but parameterized action\n",
    "3. needs noise to explore, remove it when testing (may apply other methods)<br>\n",
    "\n",
    "# How to compute the gradient of actor net\n",
    "\n",
    "1. replay memory에서 랜덤 샘플링\n",
    "2. 해당 샘플에서, actor policy를 이용해 수행할 액션 결정\n",
    "3. 해당 action을 critic에 넣고 값 산출\n",
    "4. actor network parameter에 따라 gradient 계산<br>\n",
    "\n",
    "\n",
    "# How to compute the gradient of critic net\n",
    "\n",
    "1. replay buffer에서 샘플링\n",
    "2. target actor를 이용해 새로운 상태에서의 action 산출\n",
    "3. 해당 action들을 target critic에 밀어넣어 target y 얻음\n",
    "4. 얻은 state, action을 critic에 넣고 target network의 gradient 계산<br>\n",
    "\n",
    "코드를 보면서 뭔소린지 차근차근 이해해보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import gym\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReplayBuffer 클래스\n",
    "# 그냥 똑같다. 건너뛰셈\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size, input_shape, n_actions):\n",
    "        self.mem_size = max_size\n",
    "        self.mem_cntr = 0\n",
    "        self.state_memory = np.zeros((self.mem_size, *input_shape))\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_shape))\n",
    "        self.action_memory = np.zeros((self.mem_size, n_actions))\n",
    "        self.reward_memory = np.zeros(self.mem_size)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
    "\n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.terminal_memory[index] = done\n",
    "\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "\n",
    "        batch = np.random.choice(max_mem, batch_size, replace=False)\n",
    "\n",
    "        states = self.state_memory[batch]\n",
    "        states_ = self.new_state_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        dones = self.terminal_memory[batch]\n",
    "\n",
    "        return states, actions, rewards, states_, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Critic 함수\n",
    "\n",
    "class CriticNetwork(keras.Model):\n",
    "    def __init__(self, fc1_dims=512, fc2_dims=512,\n",
    "            name='critic', chkpt_dir='ddpg'):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "\n",
    "        self.model_name = name\n",
    "        self.checkpoint_dir = chkpt_dir\n",
    "        self.checkpoint_file = os.path.join(self.checkpoint_dir, \n",
    "                    self.model_name+'_ddpg')\n",
    "\n",
    "        self.fc1 = Dense(self.fc1_dims, activation='relu')\n",
    "        self.fc2 = Dense(self.fc2_dims, activation='relu')\n",
    "        self.q = Dense(1, activation=None)\n",
    "\n",
    "    def call(self, state, action):\n",
    "        action_value = self.fc1(tf.concat([state, action], axis=1))\n",
    "        action_value = self.fc2(action_value)\n",
    "\n",
    "        q = self.q(action_value)\n",
    "\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actor Network\n",
    "\n",
    "class ActorNetwork(keras.Model):\n",
    "\n",
    "    # init함수: pendulum 환경에서는 action이 왼쪽/오른쪽, 그리고 힘의 세기로 구성된다. (그냥 -1 ~ +1 사이 값을 가진다고 보면 됨)\n",
    "    def __init__(self, fc1_dims=512, fc2_dims=512, n_actions=2, name='actor',\n",
    "            chkpt_dir='ddpg'):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "\n",
    "        self.model_name = name\n",
    "        self.checkpoint_dir = chkpt_dir\n",
    "        self.checkpoint_file = os.path.join(self.checkpoint_dir, \n",
    "                    self.model_name+'_ddpg')\n",
    "\n",
    "        self.fc1 = Dense(self.fc1_dims, activation='relu')\n",
    "        self.fc2 = Dense(self.fc2_dims, activation='relu')\n",
    "        self.mu = Dense(self.n_actions, activation='tanh')\n",
    "\n",
    "    def call(self, state):\n",
    "        prob = self.fc1(state)\n",
    "        prob = self.fc2(prob)\n",
    "        mu = self.mu(prob)\n",
    "\n",
    "        return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    # init함수: actor net이 값 변화에 더 민감하기 때문에 \n",
    "    # actor learning rate인 alpha값을 더 작게 설정\n",
    "    def __init__(self, input_dims, alpha=0.001, beta=0.002, env=None,\n",
    "                 gamma=0.99, n_actions=2, max_size=50000, tau=0.005,\n",
    "                 fc1=400, fc2=300, batch_size=64, noise=0.1):\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.memory = ReplayBuffer(max_size, input_dims, n_actions)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_actions = n_actions\n",
    "        self.noise = noise\n",
    "\n",
    "        #최대최소 action parameter 결정\n",
    "        self.max_action = env.action_space.high[0]\n",
    "        self.min_action = env.action_space.low[0]\n",
    "\n",
    "        # 네트워크 세팅\n",
    "        self.actor = ActorNetwork(n_actions=n_actions, name='actor')\n",
    "        self.critic = CriticNetwork(name='critic')\n",
    "        self.target_actor = ActorNetwork(n_actions=n_actions,\n",
    "                                        name='target_actor')\n",
    "        self.target_critic = CriticNetwork(name='target_critic')\n",
    "\n",
    "        #컴파일\n",
    "        self.actor.compile(optimizer=Adam(learning_rate=alpha))\n",
    "        self.critic.compile(optimizer=Adam(learning_rate=beta))\n",
    "        self.target_actor.compile(optimizer=Adam(learning_rate=alpha))\n",
    "        self.target_critic.compile(optimizer=Adam(learning_rate=beta))\n",
    "\n",
    "        # init()에서 실행하는 첫번째 복사이니 tau=1 실행\n",
    "        # learn에서는 self.tau로 반영\n",
    "        self.update_network_parameters(tau=1) \n",
    "\n",
    "    #soft update\n",
    "    def update_network_parameters(self, tau=None):\n",
    "        if tau is None:\n",
    "            tau = self.tau\n",
    "\n",
    "        #행동 actor에서 weight 추출 후 tau 반영해 update(actor)\n",
    "        weights = []\n",
    "        targets = self.target_actor.weights\n",
    "        for i, weight in enumerate(self.actor.weights):\n",
    "            weights.append(weight * tau + targets[i]*(1-tau))\n",
    "        self.target_actor.set_weights(weights)\n",
    "\n",
    "        #target network에서 weight 추출 후 tau 반영해 update(critic)\n",
    "        weights = []\n",
    "        targets = self.target_critic.weights\n",
    "        for i, weight in enumerate(self.critic.weights):\n",
    "            weights.append(weight * tau + targets[i]*(1-tau))\n",
    "        self.target_critic.set_weights(weights)\n",
    "\n",
    "    # store_transition wrapper\n",
    "    # 깔끔하게 OOP를 하려면 이정도는 기본\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.store_transition(state, action, reward, new_state, done)\n",
    "\n",
    "    #그냥 저장함수\n",
    "    def save_models(self):\n",
    "        #print('... saving models ...')\n",
    "        self.actor.save_weights(self.actor.checkpoint_file)\n",
    "        self.target_actor.save_weights(self.target_actor.checkpoint_file)\n",
    "        self.critic.save_weights(self.critic.checkpoint_file)\n",
    "        self.target_critic.save_weights(self.target_critic.checkpoint_file)\n",
    "\n",
    "    #그냥 로드함수\n",
    "    def load_models(self):\n",
    "        try:\n",
    "            print('... loading models ...')\n",
    "            self.actor.load_weights(self.actor.checkpoint_file)\n",
    "            self.target_actor.load_weights(self.target_actor.checkpoint_file)\n",
    "            self.critic.load_weights(self.critic.checkpoint_file)\n",
    "            self.target_critic.load_weights(self.target_critic.checkpoint_file)\n",
    "        except:\n",
    "            print('No Existing Model Found.')\n",
    "\n",
    "    # action netowork와 noise에 따라 action결정\n",
    "    # evaluate가 True이면 noise를 추가하지 않음(테스트니까)\n",
    "    def choose_action(self, observation, evaluate=False):\n",
    "        state = tf.convert_to_tensor([observation], dtype=tf.float32)\n",
    "        actions = self.actor(state)\n",
    "        #print(actions)\n",
    "        if not evaluate:\n",
    "            actions += tf.random.normal(shape=[self.n_actions],\n",
    "                                        mean=0.0, stddev=self.noise)\n",
    "\n",
    "        # tanh는 -1~1값을 가져서 그럴 일이 없지만\n",
    "        # noise때문에 action의 숫자가 적합한 범위를 초과할 수 있음\n",
    "        # action값이 가능한 action값의 min/max를 초과할 경우 clip\n",
    "        actions = tf.clip_by_value(actions, self.min_action, self.max_action)\n",
    "\n",
    "        # 하나의 action 반환\n",
    "        # 근데 왜 이렇게 했지? 이럴거면 n_action 수만큼 output node를 설정할 필요가...\n",
    "        # 알아봐주세요\n",
    "        return actions[0]\n",
    "\n",
    "    # 대망의 learn 함수\n",
    "    def learn(self):\n",
    "        if self.memory.mem_cntr < self.batch_size:\n",
    "            return\n",
    "\n",
    "        state, action, reward, new_state, done = \\\n",
    "            self.memory.sample_buffer(self.batch_size)\n",
    "\n",
    "        states  = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "        states_ = tf.convert_to_tensor(new_state, dtype=tf.float32)\n",
    "        rewards = tf.convert_to_tensor(reward, dtype=tf.float32)\n",
    "        actions = tf.convert_to_tensor(action, dtype=tf.float32)\n",
    "\n",
    "        # getting the gradient of critic net using target actor\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 1. target actor(행동 actor)를 사용해 action 산출\n",
    "            target_actions = self.target_actor(states_)\n",
    "\n",
    "            # 2. target actor가 산출한 action의 value를 target critic을 이용해 산출\n",
    "            critic_value_ = tf.squeeze(self.target_critic(\n",
    "                                states_, target_actions), 1)\n",
    "\n",
    "            # 3. 학습 critic이 산출한 action의 value 산출\n",
    "            critic_value = tf.squeeze(self.critic(states, actions), 1)\n",
    "\n",
    "            # 4. target y 계산\n",
    "            target = rewards + self.gamma*critic_value_*(1-done)\n",
    "\n",
    "            # 5. critic loss 계산: for i in batches: sum (y[i]-Q[i])^2\n",
    "            # 근데 loss계산할 때 1/n 곱하는건 은 엿바꿔먹었나?\n",
    "            # 는 아니고 MSE 함수가 해주는듯(아마 그렇겠지. 'mean' square error니까)\n",
    "            critic_loss = keras.losses.MSE(target, critic_value)\n",
    "\n",
    "        critic_network_gradient = tape.gradient(critic_loss,\n",
    "                                                self.critic.trainable_variables)\n",
    "        self.critic.optimizer.apply_gradients(zip(\n",
    "            critic_network_gradient, self.critic.trainable_variables))\n",
    "\n",
    "        # Actor loss\n",
    "        # phil 영상에서 식이 좀 잘못됨\n",
    "        # actor gain이 E[Q(s, mu(a))] 이지, actor gain gradient가 E[del Q(s, mu(a))]가 아님\n",
    "        # 논문에 의하면 actor gain gradient는 E[del Q(s, mu(a)) * del mu(a)] 임\n",
    "        # 근데 코드는 제대로 돼있음ㅋㅋ\n",
    "        with tf.GradientTape() as tape:\n",
    "            new_policy_actions = self.actor(states)\n",
    "            actor_loss = -self.critic(states, new_policy_actions)\n",
    "            actor_loss = tf.math.reduce_mean(actor_loss) #rank 1 tensor에 담겨있는 loss들 평균내기\n",
    "\n",
    "        actor_network_gradient = tape.gradient(actor_loss,\n",
    "                                               self.actor.trainable_variables)\n",
    "        self.actor.optimizer.apply_gradients(zip(\n",
    "            actor_network_gradient, self.actor.trainable_variables))\n",
    "\n",
    "        self.update_network_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function\n",
    "\n",
    "def plot_learning_curve(x, scores, figure_file):\n",
    "    running_avg = np.zeros(len(scores))\n",
    "    for i in range(len(running_avg)):\n",
    "        running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
    "    plt.plot(x, running_avg)\n",
    "    plt.title('Running average of previous 100 scores')\n",
    "    plt.savefig(figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diamo\\AppData\\Local\\Temp\\ipykernel_16132\\980999492.py:12: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading models ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diamo\\anaconda3\\envs\\RLenvironment\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] 스레드 모드가 설정된 후에는 바꿀 수 없습니다\n",
      "  warnings.warn(str(err))\n",
      "100%|██████████| 500/500 [12:07<00:00,  1.46s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = gym.make('Pendulum-v1')\n",
    "    agent = Agent(input_dims=env.observation_space.shape, env=env,\n",
    "            n_actions=env.action_space.shape[0]) #여기서는 action space shape가 [2, 1] -> shape[0] 이용\n",
    "    n_games = 500\n",
    "    games_iter = tqdm(range(n_games))\n",
    "\n",
    "    figure_file = 'plots/pendulum.png'\n",
    "\n",
    "    best_score = env.reward_range[0]\n",
    "    score_history = []\n",
    "\n",
    "    # 학습을 하고 모델을 저장한 뒤 이 값을 true로 하면, \n",
    "    # model을 로딩하고 evaluation을 true로 바꿔서\n",
    "    # test를 수행한다.\n",
    "    load_checkpoint = True\n",
    "    \n",
    "    if load_checkpoint:\n",
    "        n_steps = 0\n",
    "        while n_steps <= agent.batch_size:\n",
    "            observation = env.reset()\n",
    "            action = env.action_space.sample()\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            agent.remember(observation, action, reward, observation_, done)\n",
    "            n_steps += 1\n",
    "        agent.learn()\n",
    "        agent.load_models()\n",
    "        evaluate = True\n",
    "    else:\n",
    "        evaluate = False\n",
    "\n",
    "    for i in games_iter:\n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        while not done:\n",
    "            #print(observation)\n",
    "            action = agent.choose_action(observation, evaluate)\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "            agent.remember(observation, action, reward, observation_, done)\n",
    "            if not load_checkpoint:\n",
    "                agent.learn()\n",
    "            observation = observation_\n",
    "            env.render()\n",
    "\n",
    "        score_history.append(score)\n",
    "        avg_score = np.mean(score_history[-100:])\n",
    "\n",
    "        #성과가 더 좋아지는 경우 모델 저장\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            if not load_checkpoint:\n",
    "                agent.save_models()\n",
    "\n",
    "        #print('episode ', i, 'score %.1f' % score, 'avg score %.1f' % avg_score)\n",
    "\n",
    "    #if not load_checkpoint:\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    plot_learning_curve(x, score_history, figure_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c18703f74896985f7e04a6755cb89970ca6e351da7824f7497701b2541e2e4ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('RLenvironment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
